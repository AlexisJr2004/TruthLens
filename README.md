# ğŸ” TruthLens
### Sistema Inteligente de VerificaciÃ³n de Noticias con BERT

<div align="center">
  <img src="src/static/img/logo.png" alt="TruthLens Logo" width="200">
</div>

**TruthLens** es una aplicaciÃ³n web avanzada que utiliza inteligencia artificial para detectar noticias falsas en tiempo real. Desarrollado con un modelo BERT ajustado finamente para el espaÃ±ol, ofrece anÃ¡lisis local, privado y confiable de contenido noticioso.

---

## ğŸŒŸ CaracterÃ­sticas Principales

- **Modelo BERT Personalizado**: Fine-tuned especÃ­ficamente para noticias en espaÃ±ol
- **Procesamiento 100% Local**: Sin envÃ­o de datos a servicios externos
- **Interfaz Moderna**: Web app responsive con dark mode
- **MÃºltiples Formatos**: AnÃ¡lisis de texto, PDF, DOCX, TXT y URLs
- **OCR Opcional**: ExtracciÃ³n de texto desde imÃ¡genes
- **MÃ©tricas en Tiempo Real**: EstadÃ­sticas de uso y precisiÃ³n
- **Alta PrecisiÃ³n**: 83.05% de accuracy con F1-score de 0.826

---

## ğŸ—ï¸ Arquitectura del Proyecto

```
TruthLens/
â”œâ”€â”€ app.py                    # AplicaciÃ³n Flask principal
â”œâ”€â”€ exploratory_data_analysis.py  # Script EDA completo
â”œâ”€â”€ requirements.txt          # Dependencias Python
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ settings.py             # ConfiguraciÃ³n centralizada
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.xlsx              # Dataset de entrenamiento
â”‚   â””â”€â”€ development.xlsx        # Dataset de validaciÃ³n
â”œâ”€â”€ models/                  # Directorio del modelo BERT (crear despuÃ©s del entrenamiento)
â”‚   â””â”€â”€ truthlens_bert_model/   # Modelo entrenado
â”‚       â”œâ”€â”€ config.json
â”‚       â”œâ”€â”€ model.safetensors
â”‚       â”œâ”€â”€ tokenizer.json
â”‚       â””â”€â”€ vocab.txt
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â”œâ”€â”€ style.css        # Estilos personalizados
â”‚   â”‚   â”œâ”€â”€ main.js          # LÃ³gica principal frontend
â”‚   â”‚   â”œâ”€â”€ chatbot.js       # Sistema de recomendaciones
â”‚   â”‚   â”œâ”€â”€ reportPDF.js     # GeneraciÃ³n de reportes
â”‚   â”‚   â”œâ”€â”€ stats_analisis.json  # EstadÃ­sticas de uso
â”‚   â”‚   â”œâ”€â”€ examples.json    # Ejemplos predefinidos
â”‚   â”‚   â””â”€â”€ img/
â”‚   â”‚       â”œâ”€â”€ logo.png
â”‚   â”‚       â””â”€â”€ carga.gif
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ index.html       # Interfaz principal
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ file_extractors.py   # ExtracciÃ³n de texto de archivos
â”‚   â”œâ”€â”€ news_scraper.py      # Web scraping de noticias
â”‚   â”œâ”€â”€ recommendations.py   # Sistema de recomendaciones
â”‚   â”œâ”€â”€ response_helpers.py  # Utilidades de respuesta API
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ model_manager.py    # GestiÃ³n lazy loading de modelos
â”‚       â”œâ”€â”€ truthlens_bert.py   # Clase del modelo BERT
â”‚       â””â”€â”€ update_stats.py     # ActualizaciÃ³n de estadÃ­sticas
â”œâ”€â”€ temp/                   # Archivos temporales (auto-generado)
â”‚   â””â”€â”€ news_content_*.json     # Cache de contenido web
â”œâ”€â”€ .env                     # Variables de entorno (crear desde .env.example)
â”œâ”€â”€ .env.example            # Plantilla de configuraciÃ³n
â””â”€â”€ .gitignore              # Archivos ignorados por Git
```

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1. **Prerrequisitos**
```bash
# Python 3.8+ requerido
python --version

# Git (para clonar el repositorio)
git --version
```

### 2. **Clonar el Repositorio**
```bash
git clone https://github.com/AlexisJr2004/TruthLens.git
cd TruthLens
```

### 3. **Crear Entorno Virtual**
```bash
# Crear entorno virtual
python -m venv .venv

# Activar entorno virtual
# Windows:
.venv\Scripts\activate
# Linux/Mac:
source .venv/bin/activate
```

### 4. **Instalar Dependencias**
```bash
pip install -r requirements.txt
```

### 5. **Configurar Variables de Entorno**
```bash
# Copiar plantilla de configuraciÃ³n
cp .env.example .env

# Editar .env con tus configuraciones
# Para OCR (opcional):
OCR_SPACE_API_KEY=tu_api_key_de_ocr_space
```

### 6. **Entrenar el Modelo BERT** âš ï¸ **IMPORTANTE**

El modelo BERT no se incluye en el repositorio debido a su tamaÃ±o. Debes entrenarlo:

#### **Google Colab**
1. Abrir el notebook en Colab: [TruthLens Notebook](https://drive.google.com/file/d/1eE9YHX5G1UZrKkH2aF5sES2vAcgZsXjf/view?usp=sharing)
2. Seguir las instrucciones del notebook
3. Descargar el modelo entrenado
4. Extraer en `models/truthlens_bert_model/`

### 7. **Crear Estructura de Modelos**
```bash
# Crear directorio de modelos
mkdir -p models/truthlens_bert_model

# Extraer modelo entrenado aquÃ­
# La estructura debe ser:
# models/truthlens_bert_model/
# â”œâ”€â”€ config.json
# â”œâ”€â”€ model.safetensors
# â”œâ”€â”€ tokenizer.json
# â”œâ”€â”€ tokenizer_config.json
# â”œâ”€â”€ special_tokens_map.json
# â”œâ”€â”€ vocab.txt
# â””â”€â”€ model_summary.json
```

---

## ğŸ® Uso del Sistema

### **Iniciar la AplicaciÃ³n**
```bash
# Ejecutar aplicaciÃ³n
python app.py

# Acceder en el navegador
# http://localhost:5000
```

### **MÃ©todos de AnÃ¡lisis**

#### 1. **AnÃ¡lisis de Texto Libre**
- Pegar contenido directamente en el Ã¡rea de texto
- Incluir tÃ­tulo y contenido para mejor precisiÃ³n

#### 2. **AnÃ¡lisis de Archivos**
- Formatos soportados: PDF, DOCX, TXT
- Arrastrar y soltar o seleccionar archivo
- ExtracciÃ³n automÃ¡tica de texto

#### 3. **AnÃ¡lisis de URLs**
- Introducir enlace de noticia
- Scraping inteligente del contenido
- AnÃ¡lisis optimizado para BERT

#### 4. **AnÃ¡lisis de ImÃ¡genes (OCR)**
- Subir imagen con texto de noticia
- Requiere API key de OCR.space
- ExtracciÃ³n automÃ¡tica de texto

---

## ğŸ“Š AnÃ¡lisis Exploratorio de Datos (EDA)

### **Ejecutar AnÃ¡lisis Completo**
```bash
# AnÃ¡lisis automÃ¡tico de datasets
python exploratory_data_analysis.py

# Resultados en:
# data/eda_outputs/
# â”œâ”€â”€ eda_report_YYYYMMDD_HHMMSS.txt
# â”œâ”€â”€ distribuciones_entrenamiento.png
# â”œâ”€â”€ distribuciones_desarrollo.png
# â”œâ”€â”€ analisis_categorico_entrenamiento.png
# â”œâ”€â”€ analisis_categorico_desarrollo.png
# â”œâ”€â”€ wordclouds_entrenamiento.png
# â””â”€â”€ wordclouds_desarrollo.png
```

### **MÃ©tricas del Dataset**
- **Total de muestras**: 971 (676 train + 295 dev)
- **Balance de clases**: 50/50 True/Fake
- **Idioma**: EspaÃ±ol
- **Promedio de palabras**: ~400 palabras por artÃ­culo

---

## ğŸ“ˆ Rendimiento del Modelo

### **MÃ©tricas de EvaluaciÃ³n**

| MÃ©trica | Valor | DescripciÃ³n |
|---------|-------|-------------|
| **Accuracy** | 83.05% | PrecisiÃ³n general del modelo |
| **F1-Score** | 0.826 | Balance entre precisiÃ³n y recall |
| **PrecisiÃ³n (True)** | 85.2% | DetecciÃ³n correcta de noticias verdaderas |
| **PrecisiÃ³n (Fake)** | 80.9% | DetecciÃ³n correcta de noticias falsas |
| **Recall (True)** | 82.1% | Cobertura de noticias verdaderas |
| **Recall (Fake)** | 84.2% | Cobertura de noticias falsas |

### **CalibraciÃ³n Inteligente**

El sistema implementa calibraciÃ³n adaptativa:
- **Alta Confianza** (diff > 0.5): Umbral conservador (0.65)
- **Confianza Media** (diff 0.3-0.5): Umbral moderado (0.75)
- **Baja Confianza** (diff < 0.3): Umbral estricto (0.85)

---

## ğŸ”’ Privacidad y Seguridad

### **Procesamiento Local**
- âœ… Modelo BERT ejecutado localmente
- âœ… Sin envÃ­o de datos a terceros
- âœ… AnÃ¡lisis offline disponible
- âš ï¸ OCR requiere servicio externo (opcional)

### **Datos Temporales**
- Archivos temporales en `/temp/`
- Auto-limpieza periÃ³dica
- Sin almacenamiento permanente de contenido usuario

---

## ğŸ› ï¸ ConfiguraciÃ³n Avanzada

### **Variables de Entorno (.env)**
```bash
# Flask Configuration
FLASK_ENV=development          # development | production
FLASK_DEBUG=True              # True | False

# Model Configuration
BERT_MODEL_PATH=models/truthlens_bert_model

# OCR Configuration (opcional)
OCR_SPACE_API_KEY=tu_api_key
OCR_API_URL=https://api.ocr.space/parse/image
```

---

## ğŸ“š DocumentaciÃ³n TÃ©cnica

### **Arquitectura del Modelo**
- **Base**: `dccuchile/bert-base-spanish-wwm-uncased`
- **Capas**: 12 transformer layers
- **ParÃ¡metros**: ~110M parÃ¡metros
- **Vocabulario**: 31,002 tokens en espaÃ±ol
- **Secuencia mÃ¡xima**: 512 tokens

### **Pipeline de Procesamiento**
1. **Limpieza de texto**: EliminaciÃ³n de URLs, caracteres especiales
2. **TokenizaciÃ³n**: BERT tokenizer con padding/truncating
3. **Inferencia**: Forward pass del modelo
4. **CalibraciÃ³n**: Ajuste dinÃ¡mico de umbral
5. **Respuesta**: Formato JSON con metadatos

### **Optimizaciones Implementadas**
- Lazy loading del modelo
- Cacheo en memoria
- SelecciÃ³n automÃ¡tica GPU/CPU
- Procesamiento por lotes (batch processing)
- Truncado inteligente por pÃ¡rrafos

---

## ğŸ“– Referencias y Dataset

### **Dataset Original**
- **Fuente**: [FakeNewsCorpusSpanish](https://github.com/jpposadas/FakeNewsCorpusSpanish)
- **Autor**: Posadas-DurÃ¡n et al. (2019)
- **Licencia**: AcadÃ©mica/InvestigaciÃ³n
- **Idioma**: EspaÃ±ol

### **Modelo Base**
- **BERT EspaÃ±ol**: `dccuchile/bert-base-spanish-wwm-uncased`
- **Desarrollado por**: Universidad de Chile
- **Pre-entrenado en**: Corpus masivo en espaÃ±ol

### **TecnologÃ­as Clave**
- **Framework ML**: PyTorch, Transformers (Hugging Face)
- **Web Framework**: Flask
- **Frontend**: HTML5, CSS3, JavaScript (Vanilla)
- **AnÃ¡lisis de Datos**: Pandas, Matplotlib, Seaborn
- **Scraping**: BeautifulSoup4, Requests
- **OCR**: OCR.space API

---

## ğŸ“„ Licencia y TÃ©rminos de Uso

### **Uso AcadÃ©mico y Educativo**
Este proyecto estÃ¡ diseÃ±ado principalmente para:
- InvestigaciÃ³n acadÃ©mica en NLP
- EducaciÃ³n en IA y detecciÃ³n de desinformaciÃ³n
- Desarrollo de herramientas de verificaciÃ³n

### **Limitaciones**
- No garantiza 100% de precisiÃ³n
- Requiere validaciÃ³n humana para decisiones crÃ­ticas
- Optimizado para noticias en espaÃ±ol
- Dataset de entrenamiento limitado

### **Responsabilidad**
Los usuarios son responsables de:
- Verificar resultados independientemente
- No usar como Ãºnica fuente de verdad
- Respetar derechos de autor del contenido analizado

---

## ğŸ‘¥ CrÃ©ditos y Reconocimientos

### **Desarrollado por**
- **TruthLens Team** - Desarrollo principal
- **Posadas-DurÃ¡n et al.** - Dataset original
- **Hugging Face** - Framework Transformers
- **Universidad de Chile** - Modelo BERT base

### **Contribuciones Especiales**
- Comunidad de investigadores en NLP espaÃ±ol
- Desarrolladores de bibliotecas open source utilizadas
- Beta testers y usuarios que proporcionaron feedback

---

## ğŸ“ Soporte y Contacto

### **Comunidad y Contribuciones**
- ğŸ› **Issues**: Reportar bugs y solicitar caracterÃ­sticas
- ğŸ”„ **Pull Requests**: Contribuciones de cÃ³digo
- ğŸ’¡ **Discussions**: Ideas y mejoras generales
- ğŸ“§ **Email**: snietod@unemi.edu.ec

---

**Â¿Listo para detectar fake news con IA? Â¡Empieza instalando TruthLens!** ğŸš€

```bash
git clone https://github.com/AlexisJr2004/TruthLens.git
cd TruthLens
pip install -r requirements.txt
python app.py
```

*Desarrollado con â¤ï¸ para combatir la desinformaciÃ³n*
